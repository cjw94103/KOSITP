{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c3d030-41e1-49dd-8202-5b3d06c33ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "from transformers import TextStreamer\n",
    "from utils import load_jsonl_file\n",
    "from make_args import Args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0841d183-b7d4-4b72-80b9-40246dc5d6df",
   "metadata": {},
   "source": [
    "- Instruction Formatting 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27084d8b-c817-405b-8d7e-75a30ad8a437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(x):\n",
    "    return f\"###입력:{x}\\n\\n###출력:\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25294a2-48f7-4875-ae6a-f142107f8f00",
   "metadata": {},
   "source": [
    "- load args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ec41ccf-3c0b-4604-ba00-01d57cf952d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args('./config/SOLAR_train_config.json')\n",
    "args.output_dir = './model_result/01_02_SoLAR_10.7B_Unsloth_AIHUBKistiWebDataset/checkpoint-29433/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce2b60b-8a9e-40d5-9a5c-fef1c7877f3f",
   "metadata": {},
   "source": [
    "- load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02ff831b-ecf1-4514-b193-d4e7b976f743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Llama patching release 2024.3\n",
      "   \\\\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.2.1. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. Xformers = 0.0.25. FA = False.\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1d1673cf1c4dda8c392de3573a1987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.3 patched 48 layers with 48 QKV layers, 48 O layers and 48 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = args.max_seq_length\n",
    "dtype = None \n",
    "load_in_4bit = True\n",
    "model_name = args.output_dir\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name , ,
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    device_map='auto'\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053369ef-b90c-4989-940a-12bbc296c8c9",
   "metadata": {},
   "source": [
    "- Fast Inference mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0d2b6f6-e071-4480-ae86-eece56313d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fb5b6d-3e9e-4994-937b-b6cb2195dbd7",
   "metadata": {},
   "source": [
    "- TextStreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6d9649d-0826-466e-a1a0-125d1708e7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = TextStreamer(tokenizer, skip_prompt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf32d95c-cdca-479c-86ac-26680cef2424",
   "metadata": {},
   "source": [
    "- 입력 데이터를 Instruction Format으로 변환 후 tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2259b36a-e624-4efe-9236-8fba5db615da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> ###입력:당신은 경영 컨설턴트 비서 인공지능입니다. 친절하게 설명해주세요. 답이 어렵다면 단계별로 설명해주세요.\\n\\nESG 경영이란 무엇인가?\\n\\n###출력:'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = \"\"\"당신은 경영 컨설턴트 비서 인공지능입니다. 친절하게 설명해주세요. 답이 어렵다면 단계별로 설명해주세요.\\n\\n\"\"\"\n",
    "instruction = \"ESG 경영이란 무엇인가?\"\n",
    "\n",
    "input_text = preprocess_text(system_prompt + instruction)\n",
    "input_tokens = tokenizer(input_text, return_tensors='pt', return_token_type_ids=False)\n",
    "\n",
    "tokenizer.decode(input_tokens['input_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5344a9-3a8a-4d86-8d5f-dfe09617438d",
   "metadata": {},
   "source": [
    "- 그리드 서치 디코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a0e55b9-ec60-4b7b-bf3e-dcd3826b6a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESG 경영은 기업이 환경, 사회, 지배 구조에 대한 영향력을 고려하여 경영하는 접근 방식입니다. 이는 기업이 사회적 책임을 다하고 지속 가능한 비즈니스 모델을 구축하는 것을 강조합니다. \n",
      "\n",
      "\"E\"는 환경을 의미하며, 기업이 환경에 미치는 영향을 고려하고 친환경 방식으로 운영하는 것을 의미합니다. 이는 기업이 탄소 배출을 줄이고 재활용을 촉진하며 지속 가능한 에너지 소스를 사용하는 등의 방법으로 환경에 대한 영향을 최소화하는 것을 의미합니다.\n",
      "\n",
      "\"S\"는 사회를 의미하며, 기업이 사회에 미치는 영향을 고려하고 사회적 책임을 다하는 것을 의미합니다. 이는 기업이 다양성과 포용성을 증진하고 공정한 노동 조건을 제공하며 지역 사회에 기여하는 등의 방법으로 사회에 긍정적인 영향을 미치는 것을 의미합니다.\n",
      "\n",
      "\"G\"는 지배 구조를 의미하며, 기업이 지배 구조에 대한 영향력을 고려하고 투명하고 윤리적인 방식으로 운영하는 것을 의미합니다. 이는 기업이 독립적인 이사회를 구성하고 공정한 거래를 하며 공정한 보상 체계를 구축하는 등의 방법으로 지배 구조에 대한 영향력을 최소화하는 것을 의미합니다.\n",
      "\n",
      "ESG 경영은 기업이 사회적 책임을 다하고 지속 가능한 비즈니스 모델을 구축하는 것을 강조하는 접근 방식입니다. 이는 기업이 환경, 사회, 지배 구조에 대한 영향력을 고려하여 경영하는 것을 의미합니다.$&%</s>\n"
     ]
    }
   ],
   "source": [
    "result = model.generate(**input_tokens,\n",
    "                        max_new_tokens=1024, early_stopping=True, do_sample=False, eos_token_id=2, pad_token_id=2, temperature=0.7,\n",
    "                        streamer=streamer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5c2691-dac2-4b7a-9a12-cbcdff07d400",
   "metadata": {},
   "source": [
    "- vLLM 추론을 위한 merged_16bit를 이용하여 lora_adapter 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f75802f-af9c-4c1a-9197-865ae66bb1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained_merged('merged_model', tokenizer, save_method=\"merged_16bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1931c1-b8b4-4fb2-abdc-80ef050941e8",
   "metadata": {},
   "source": [
    "- lora adapter만 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aa49a1-654b-48ed-a4c5-291b9d03f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained_merged('lora_model', tokenizer, save_method=\"lora\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_torch",
   "language": "python",
   "name": "unsloth_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
