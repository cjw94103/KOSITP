{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97ce726f-054e-43db-a4fd-758d1823f443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aicombined/miniconda3/envs/poc/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-17 16:30:52,316\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dca7dcf-d5c6-42c0-a054-d2d65d196055",
   "metadata": {},
   "source": [
    "- Instruction Formatting 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "081eaae8-453c-476a-8fe9-1db1b14f6451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(x):\n",
    "    return f\"###입력:{x}\\n\\n###출력:\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e688be0d-18b2-4158-a9dd-275c6ba6deff",
   "metadata": {},
   "source": [
    "- merge_16bit로 저장된 모델 weight의 폴더를 이용하여 llm를 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d3d294-6c07-4ffa-a4ea-7fed48fe61de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-17 16:30:59 llm_engine.py:100] Initializing an LLM engine (v0.4.2) with config: model='huggingface_merged_weights/SOLAR/', speculative_config=None, tokenizer='huggingface_merged_weights/SOLAR/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=huggingface_merged_weights/SOLAR/)\n",
      "INFO 06-17 16:30:59 utils.py:660] Found nccl from library /home/aicombined/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "INFO 06-17 16:31:00 selector.py:81] Cannot use FlashAttention-2 backend because the flash_attn package is not found. Please install it for better performance.\n",
      "INFO 06-17 16:31:00 selector.py:32] Using XFormers backend.\n",
      "INFO 06-17 16:31:13 model_runner.py:175] Loading model weights took 19.9939 GB\n",
      "INFO 06-17 16:31:16 gpu_executor.py:114] # GPU blocks: 7431, # CPU blocks: 1365\n",
      "INFO 06-17 16:31:19 model_runner.py:937] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 06-17 16:31:19 model_runner.py:941] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 06-17 16:31:27 model_runner.py:1017] Graph capturing finished in 8 secs.\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model=\"huggingface_merged_weights/SOLAR/\", enable_lora=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f41fa0d-8d52-45bd-b845-272e5c18a21f",
   "metadata": {},
   "source": [
    "- 자연어 생성을 위한 그리드 서치 디코딩 파라미터 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e4e324-9c71-478a-bfe9-f83591ab44ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(max_tokens=256, temperature=0.5, top_k=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d33e5e-f6f2-4aea-8520-d9149115cac8",
   "metadata": {},
   "source": [
    "- 입력 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15ffef7a-2095-4863-bf3b-aacda8ec2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"당신은 경영 컨설턴트 비서 인공지능입니다. 답이 어렵다면 단계별로 설명해주세요.\\n\\n\"\"\"\n",
    "instruction = \"ESG 경영이란 무엇인가?\"\n",
    "texts = [preprocess_text(system_prompt + instruction)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a4c959-fa7d-4a41-8ad8-00fdc86132f6",
   "metadata": {},
   "source": [
    "- inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d62aaacc-2e36-4678-b8a8-951e6dcaf6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.89s/it]\n"
     ]
    }
   ],
   "source": [
    "outputs = llm.generate(texts, sampling_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0069b3ed-d6b6-4419-b6f4-93e9703b8d2f",
   "metadata": {},
   "source": [
    "- 생성 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81103289-eb73-4d5d-8fa8-a7e1fa3feb65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('###입력:당신은 경영 컨설턴트 비서 인공지능입니다. 답이 어렵다면 단계별로 설명해주세요.\\n\\nESG 경영이란 무엇인가?\\n\\n###출력:',\n",
       " 'ESG 경영은 기업이 사회적 책임, 환경 지속 가능성 및 윤리적 지배 구조에 대한 접근 방식을 강조하는 경영 방식입니다. 이는 기업이 사회적 책임을 이행하고 환경적 영향을 최소화하며 공정하고 투명한 지배 구조를 유지하는 것을 의미합니다. ESG 경영 접근 방식은 기업의 지속 가능성을 향상시키고 장기적으로 성과를 향상시키는 데 도움이 될 수 있습니다. 이는 기업의 재무적 건전성과 이익을 향상시키는 데 도움이 될 수 있습니다.$&%')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "prompt, generated_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poc",
   "language": "python",
   "name": "poc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
