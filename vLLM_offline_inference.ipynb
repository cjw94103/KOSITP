{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97ce726f-054e-43db-a4fd-758d1823f443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aicombined/miniconda3/envs/poc/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-17 16:00:11,625\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dca7dcf-d5c6-42c0-a054-d2d65d196055",
   "metadata": {},
   "source": [
    "- Instruction Formatting 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "081eaae8-453c-476a-8fe9-1db1b14f6451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(x):\n",
    "    return f\"###입력:{x}\\n\\n###출력:\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e688be0d-18b2-4158-a9dd-275c6ba6deff",
   "metadata": {},
   "source": [
    "- merge_16bit로 저장된 모델 weight의 폴더를 이용하여 llm를 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d3d294-6c07-4ffa-a4ea-7fed48fe61de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-17 16:00:53 llm_engine.py:100] Initializing an LLM engine (v0.4.2) with config: model='merged_model/', speculative_config=None, tokenizer='merged_model/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=merged_model/)\n",
      "INFO 06-17 16:00:53 utils.py:660] Found nccl from library /home/aicombined/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "INFO 06-17 16:00:54 selector.py:81] Cannot use FlashAttention-2 backend because the flash_attn package is not found. Please install it for better performance.\n",
      "INFO 06-17 16:00:54 selector.py:32] Using XFormers backend.\n",
      "INFO 06-17 16:01:07 model_runner.py:175] Loading model weights took 19.9939 GB\n",
      "INFO 06-17 16:01:09 gpu_executor.py:114] # GPU blocks: 7431, # CPU blocks: 1365\n",
      "INFO 06-17 16:01:12 model_runner.py:937] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 06-17 16:01:12 model_runner.py:941] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 06-17 16:01:20 model_runner.py:1017] Graph capturing finished in 8 secs.\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model=\"merged_model/\", enable_lora=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f41fa0d-8d52-45bd-b845-272e5c18a21f",
   "metadata": {},
   "source": [
    "- 자연어 생성을 위한 그리드 서치 디코딩 파라미터 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e4e324-9c71-478a-bfe9-f83591ab44ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(max_tokens=512, temperature=0.5, top_k=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d33e5e-f6f2-4aea-8520-d9149115cac8",
   "metadata": {},
   "source": [
    "- 입력 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15ffef7a-2095-4863-bf3b-aacda8ec2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"당신은 경영 컨설턴트 비서 인공지능입니다. 답이 어렵다면 단계별로 설명해주세요.\\n\\n\"\"\"\n",
    "instruction = \"ESG 경영이란 무엇인가?\"\n",
    "texts = [preprocess_text(system_prompt + instruction)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a4c959-fa7d-4a41-8ad8-00fdc86132f6",
   "metadata": {},
   "source": [
    "- inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d62aaacc-2e36-4678-b8a8-951e6dcaf6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.13s/it]\n"
     ]
    }
   ],
   "source": [
    "outputs = llm.generate(texts, sampling_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0069b3ed-d6b6-4419-b6f4-93e9703b8d2f",
   "metadata": {},
   "source": [
    "- 생성 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81103289-eb73-4d5d-8fa8-a7e1fa3feb65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('###입력:당신은 경영 컨설턴트 비서 인공지능입니다. 답이 어렵다면 단계별로 설명해주세요.\\n\\nESG 경영이란 무엇인가?\\n\\n###출력:',\n",
       " '환경(Environment), 사회(Social), 지배구조(Governance)의 약자로 기업의 사회적 책임과 공유가치 창출을 통해 지속가능한 발전을 추구하는 경영이다. 환경은 기업의 사회적 책임(CSR), 사회는 사회적 가치(SV), 지배구조는 경영투명성과 윤리성(Governance)을 의미한다.$&%')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "prompt, generated_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poc",
   "language": "python",
   "name": "poc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
