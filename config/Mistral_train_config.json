{
    "train_path": "../01_Data_Processing/processed_data/01_SuperNITaskDataset_Whole/03_03_Integration_TrainVal/Trainset.jsonl",
    "val_path": "../01_Data_Processing/processed_data/01_SuperNITaskDataset_Whole/03_03_Integration_TrainVal/Valset.jsonl",
    "max_seq_length": 2048,
    "pretrained_model_name": "davidkim205/komt-mistral-7b-v1",
    "lora_r": 8,
    "lora_alpha": 32,
    "lora_target_modules": [
        "q_proj",
        "k_proj",
        "v_proj",
        "o_proj",
        "gate_proj",
        "up_proj",
        "down_proj"
    ],
    "lora_dropout": 0.0,
    "use_gradient_checkpointing": true,
    "random_state": 3407,
    "use_rslora": false,
    "num_train_epochs": 3,
    "train_batch_size": 4,
    "eval_batch_size": 4,
    "gradient_accumulation_steps": 4,
    "weight_decay": 0.01,
    "evaluation_strategy": "steps",
    "save_steps": 9811,
    "eval_steps": 9811,
    "learning_rate": 0.0002,
    "logging_steps": 100,
    "output_dir": "model_result/Mistral_Test",
    "optim": "adamw_8bit",
    "load_best_model_at_end": true,
    "save_total_limit": 3,
    "packing": false,
    "model_use_cache": false
}