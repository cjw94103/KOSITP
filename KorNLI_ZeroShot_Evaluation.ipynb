{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad8ef277-c97f-434c-87a4-4720702318aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aicombined/miniconda3/envs/poc/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-17 20:54:22,631\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from vllm import LLM, SamplingParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b01b03-794b-471e-afd4-ae0f9cc82939",
   "metadata": {},
   "source": [
    "- Instruction Formatting 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cb49bc8-7de4-4e36-bb37-616f362bb143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(x):\n",
    "    return f\"###입력:{x}\\n\\n###출력:\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6e1b15-5ce1-4118-949b-ca85d65bd614",
   "metadata": {},
   "source": [
    "- merge_16bit로 저장된 모델 weight의 폴더를 이용하여 llm를 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c02c57ea-a762-4d3f-ad3a-53f1d00b70e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-17 20:54:23 llm_engine.py:100] Initializing an LLM engine (v0.4.2) with config: model='huggingface_merged_weights/SOLAR/', speculative_config=None, tokenizer='huggingface_merged_weights/SOLAR/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=huggingface_merged_weights/SOLAR/)\n",
      "INFO 06-17 20:54:23 utils.py:660] Found nccl from library /home/aicombined/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "INFO 06-17 20:54:24 selector.py:81] Cannot use FlashAttention-2 backend because the flash_attn package is not found. Please install it for better performance.\n",
      "INFO 06-17 20:54:24 selector.py:32] Using XFormers backend.\n",
      "INFO 06-17 20:54:36 model_runner.py:175] Loading model weights took 19.9939 GB\n",
      "INFO 06-17 20:54:39 gpu_executor.py:114] # GPU blocks: 7431, # CPU blocks: 1365\n",
      "INFO 06-17 20:54:41 model_runner.py:937] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 06-17 20:54:41 model_runner.py:941] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 06-17 20:54:49 model_runner.py:1017] Graph capturing finished in 8 secs.\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model=\"huggingface_merged_weights/SOLAR/\", enable_lora=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa017a6e-b9b0-4140-bbe0-63ab733f8b03",
   "metadata": {},
   "source": [
    "- 자연어 생성을 위한 그리드 서치 디코딩 파라미터 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91c5d470-5e2a-4279-8b93-50425c0df634",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(max_tokens=256, temperature=0.5, top_k=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123f187b-89b6-4e4b-8061-fcedd086bdca",
   "metadata": {},
   "source": [
    "- korea_hate_speech 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ac7d70c-141b-4676-b64b-7482bd20f6b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences1 = []\n",
    "sentences2 = []\n",
    "labels = []\n",
    "\n",
    "with open('./evaluation_dataset/03_kor_nli/xnli.test.ko.tsv', 'r') as f:\n",
    "    kornli_data = f.readlines()\n",
    "        \n",
    "for data in kornli_data[1:]:\n",
    "    data_split = data.split('\\t')\n",
    "    sentence1 = data_split[0]\n",
    "    sentence2 = data_split[1]\n",
    "    label = data_split[2].split('\\n')[0]\n",
    "\n",
    "    sentences1.append(sentence1)\n",
    "    sentences2.append(sentence2)\n",
    "\n",
    "    if label == 'contradiction':\n",
    "        labels.append('모순')\n",
    "    elif label == 'neutral':\n",
    "        labels.append('중립')\n",
    "    elif label == 'entailment':\n",
    "        labels.append('함의')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc82bda0-8efe-433f-a533-557efbd12387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('글쎄, 나는 그것에 관해 생각조차 하지 않았지만, 나는 너무 좌절했고, 결국 그에게 다시 이야기하게 되었다.',\n",
       " '나는 그와 다시 이야기하지 않았다.',\n",
       " '모순')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences1[0], sentences2[0], labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b695ef-e63e-4262-a120-9497ddd4417a",
   "metadata": {},
   "source": [
    "- 입력 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0544cdf6-0078-4a55-b830-1ffaef6085a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"문장1과 문장 2의 관계에 대하여 함의 또는 중립 또는 모순으로 대답하세요. 문장 2가 논리적으로 문장 1을 따르는 경우 함의이고 문장 2와 문장 1의 논리적인 관계가 분명하지 않을 경우 중립이며 문장 2가 문장 1과 반대되는 경우는 모순입니다.\\n\\n\"\"\"\n",
    "texts = []\n",
    "\n",
    "for sentence1, sentence2, label in zip(sentences1, sentences2, labels):\n",
    "    instruction = \"문장 1 : {} \\n 문장 2 : {}\".format(sentence1, sentence2)\n",
    "    texts.append(preprocess_text(system_prompt + instruction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82ff474e-d280-4963-aa63-3ce612484d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'###입력:문장1과 문장 2의 관계에 대하여 함의 또는 중립 또는 모순으로 대답하세요. 문장 2가 논리적으로 문장 1을 따르는 경우 함의이고 문장 2와 문장 1의 논리적인 관계가 분명하지 않을 경우 중립이며 문장 2가 문장 1과 반대되는 경우는 모순입니다.\\n\\n문장 1 : 글쎄, 나는 그것에 관해 생각조차 하지 않았지만, 나는 너무 좌절했고, 결국 그에게 다시 이야기하게 되었다. \\n 문장 2 : 나는 그와 다시 이야기하지 않았다.\\n\\n###출력:'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182d7249-e686-4d30-82c7-4fd4c6c9687f",
   "metadata": {},
   "source": [
    "- inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce96455d-1a0d-47ec-9c2c-1783c85355ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 5010/5010 [05:06<00:00, 16.37it/s]\n"
     ]
    }
   ],
   "source": [
    "outputs = llm.generate(texts, sampling_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af87919b-c6f5-46e9-a785-39c2c5986970",
   "metadata": {},
   "source": [
    "- 생성 결과 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f948b099-b9c3-4bd3-b8c2-78211a4a90cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for output in outputs:\n",
    "    generated_text = output.outputs[0].text\n",
    "    preds.append(generated_text.split('$&%')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12f36b05-2d10-49a5-867d-6c24d5b4e1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_processed = []\n",
    "labels_processed = []\n",
    "\n",
    "for y_pred, y_true in zip(preds, labels):\n",
    "    if y_pred == '모순' or y_pred == '중립' or y_pred == '함의':\n",
    "        preds_processed.append(y_pred)\n",
    "        labels_processed.append(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f48c858-ceb5-4139-8a7a-e73855537202",
   "metadata": {},
   "source": [
    "- zero-shot 분류 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "529953c6-487e-4733-8576-9e3ab13ee038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          모순       0.49      0.95      0.65      1663\n",
      "          중립       0.62      0.07      0.13      1614\n",
      "          함의       0.59      0.53      0.56      1569\n",
      "\n",
      "    accuracy                           0.52      4846\n",
      "   macro avg       0.56      0.52      0.44      4846\n",
      "weighted avg       0.56      0.52      0.44      4846\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels_processed, preds_processed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poc",
   "language": "python",
   "name": "poc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
